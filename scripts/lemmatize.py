# Takes a clean file or directory, then tokenizes and lemmatizes it
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

nltk.download('punkt') 
nltk.download('wordnet')


